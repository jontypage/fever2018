{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading archive file ../roberta.large.mnli\n",
      "| dictionary: 50264 types\n",
      "tensor(1)\n",
      "tensor(2)\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from fairseq.models.roberta import RobertaModel\n",
    "roberta = RobertaModel.from_pretrained('../roberta.large.mnli', checkpoint_file='model.pt')\n",
    "roberta.eval()  # disable dropout (or leave in train mode to finetune)\n",
    "\n",
    "# Encode a pair of sentences and make a prediction\n",
    "tokens = roberta.encode('[ Ramona and Beezus ] Fox 2000 Pictures released the film on July 23 , 2010 .', 'Fox 2000 Pictures released the film Soul Food .')\n",
    "print(roberta.predict('mnli', tokens).argmax())  # 0: contradiction\n",
    "\n",
    "tokens = roberta.encode('Robert is a heavily optimized version of BERT', 'Roberta is based on BERT.')\n",
    "print(roberta.predict('mnli', tokens).argmax()) # 2: entailment\n",
    "\n",
    "tokens = roberta.encode('Jonty is a chef.', 'Jonty hates cooking.')\n",
    "print(roberta.predict('mnli', tokens).argmax())  # 0: contradiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|███████████████▉                 | 39913/82555 [00:00<00:00, 399125.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ../data/fever/dev\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from text_utils import TextEncoder\n",
    "from datasets import _entailment, entailment\n",
    "from utils import encode_dataset\n",
    "\n",
    "text_encoder = TextEncoder('model/encoder_bpe_40000.json', 'model/vocab_40000.bpe')\n",
    "test_prefix = '../data/fever/dev'\n",
    "tst_premise, tst_hypothesis, tst_y = _entailment(test_prefix)\n",
    "test_set = encode_dataset([(tst_premise, tst_hypothesis, tst_y)], encoder=text_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import re\n",
    "import math\n",
    "from tqdm import tqdm_notebook\n",
    "from fairseq.models.roberta import RobertaModel\n",
    "from fairseq.data.data_utils import collate_tokens\n",
    "\n",
    "\n",
    "def predict(tst_premise, tst_hypothesis, batch_size, result_file):\n",
    "    roberta = RobertaModel.from_pretrained('../roberta.large.mnli', checkpoint_file='model.pt')\n",
    "    roberta.eval()  # disable dropout (or leave in train mode to finetune)\n",
    "    predictions = []\n",
    "    print(\"Running predictions\")\n",
    "    \n",
    "    list_of_pairs = list(zip(tst_premise, tst_hypothesis))\n",
    "    for i in tqdm_notebook(range(1)):#range(math.ceil(len(tst_premise)/batch_size))):\n",
    "        batch = collate_tokens(\n",
    "            [roberta.encode(pair[0], pair[1]) for pair in list_of_pairs[i*batch_size:(i+1)*batch_size]], pad_idx=1\n",
    "        )\n",
    "        try:\n",
    "            logprobs = roberta.predict('mnli', batch)\n",
    "            print(logprobs)\n",
    "            predictions = predictions + logprobs.argmax(dim=1).tolist()\n",
    "            print(predictions)\n",
    "        except:\n",
    "            print('I made it')\n",
    "            predictions = predictions + torch.ones([batch.shape[0]], dtype=torch.long).tolist()\n",
    "    \n",
    "    print(\"Succeeded\")\n",
    "    \n",
    "    with open(result_file, 'w') as f:\n",
    "        f.write('{}\\t{}\\n'.format('index', 'prediction'))\n",
    "        for i, prediction in enumerate(predictions):\n",
    "            print(i)\n",
    "            print(prediction)\n",
    "            f.write('{}\\t{}\\n'.format(i, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading archive file ../roberta.large.mnli\n",
      "| dictionary: 50264 types\n",
      "Running predictions\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33eac5043dc54a3f8977fd3d3cfbe675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-5.2041e+00, -7.0819e-02, -2.7666e+00],\n",
      "        [-2.1173e-02, -3.9987e+00, -5.9478e+00],\n",
      "        [-4.7036e+00, -1.9429e-02, -4.5874e+00],\n",
      "        [-3.6511e+00, -1.3335e-01, -2.3139e+00],\n",
      "        [-4.1180e+00, -2.2018e-02, -5.2031e+00],\n",
      "        [-4.4458e-01, -1.0342e+00, -5.6868e+00],\n",
      "        [-8.9010e-01, -5.3388e-01, -5.7897e+00],\n",
      "        [-1.2008e+00, -3.6301e-01, -5.6686e+00],\n",
      "        [-1.4514e-01, -2.0230e+00, -5.8640e+00],\n",
      "        [-3.6590e-01, -1.1976e+00, -5.4004e+00],\n",
      "        [-2.5911e+00, -8.6441e-02, -4.8448e+00],\n",
      "        [-5.0400e+00, -4.7121e+00, -1.5581e-02],\n",
      "        [-3.1549e+00, -4.5192e-02, -6.4733e+00],\n",
      "        [-3.9246e+00, -7.0360e-02, -3.0326e+00],\n",
      "        [-4.4295e+00, -4.1976e-02, -3.5340e+00],\n",
      "        [-7.6944e-04, -7.4795e+00, -8.4944e+00],\n",
      "        [-6.1946e-04, -7.8702e+00, -8.3460e+00],\n",
      "        [-7.1738e-04, -7.6221e+00, -8.3880e+00],\n",
      "        [-1.5905e-03, -7.0436e+00, -7.2414e+00],\n",
      "        [-5.6353e-03, -5.4054e+00, -6.7881e+00],\n",
      "        [-5.1409e+00, -4.4143e+00, -1.8118e-02],\n",
      "        [-4.9065e+00, -4.2926e+00, -2.1293e-02],\n",
      "        [-4.7345e+00, -4.0061e+00, -2.7362e-02],\n",
      "        [-5.1970e+00, -4.2472e+00, -2.0037e-02],\n",
      "        [-5.3519e+00, -4.5748e+00, -1.5162e-02],\n",
      "        [-1.2795e-01, -2.2285e+00, -4.3892e+00],\n",
      "        [-2.7059e-01, -1.4702e+00, -4.9360e+00],\n",
      "        [-2.9550e-01, -1.3878e+00, -5.0799e+00],\n",
      "        [-4.0945e-02, -3.2565e+00, -6.4399e+00],\n",
      "        [-1.3125e+00, -3.1964e-01, -5.4185e+00],\n",
      "        [-2.3812e+00, -1.0765e-01, -4.6443e+00],\n",
      "        [-3.1976e+00, -4.9834e-02, -4.8597e+00]], grad_fn=<LogSoftmaxBackward>)\n",
      "[1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 2, 1, 1, 1, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 1, 1]\n",
      "\n",
      "Succeeded\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "3\n",
      "1\n",
      "4\n",
      "1\n",
      "5\n",
      "0\n",
      "6\n",
      "1\n",
      "7\n",
      "1\n",
      "8\n",
      "0\n",
      "9\n",
      "0\n",
      "10\n",
      "1\n",
      "11\n",
      "2\n",
      "12\n",
      "1\n",
      "13\n",
      "1\n",
      "14\n",
      "1\n",
      "15\n",
      "0\n",
      "16\n",
      "0\n",
      "17\n",
      "0\n",
      "18\n",
      "0\n",
      "19\n",
      "0\n",
      "20\n",
      "2\n",
      "21\n",
      "2\n",
      "22\n",
      "2\n",
      "23\n",
      "2\n",
      "24\n",
      "2\n",
      "25\n",
      "0\n",
      "26\n",
      "0\n",
      "27\n",
      "0\n",
      "28\n",
      "0\n",
      "29\n",
      "1\n",
      "30\n",
      "1\n",
      "31\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "predict(tst_premise, tst_hypothesis, 32, '../data/fever/roberta_results_file_dev_asdgfasldkfjsan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_utils import TextEncoder\n",
    "from datasets import _entailment, entailment\n",
    "from utils import encode_dataset\n",
    "\n",
    "text_encoder = TextEncoder('model/encoder_bpe_40000.json', 'model/vocab_40000.bpe')\n",
    "test_prefix = '../data/fever-copy/test'\n",
    "tst_premise_short, tst_hypothesis_short, tst_y_short = _entailment(test_prefix)\n",
    "test_set_short = encode_dataset([(tst_premise_short, tst_hypothesis_short, tst_y_short)], encoder=text_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import sys\n",
    "\n",
    "\n",
    "predicted = []\n",
    "\n",
    "with open('../data/fever/dev-predictions.jsonl',\"r\") as predictions_file:\n",
    "    for line in predictions_file:\n",
    "        predicted.append(json.loads(line)['predicted_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
